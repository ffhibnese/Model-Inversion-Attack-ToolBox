# Path Tutorial

## Experiment Folder

The experiment folder is the folder where the experiment results are saved.

## Dataset

### CelebA

To use CelebA dataset, please follow [here](./datasets.md) to download and preprocess the dataset.

The preprocessed CelebA dataset is organized into the following structure:
```
<celeba_preprocessed_path>
├── public
├── private_train
└── private_test
```

To access the dataset, the `dataset_path` format should follow `<celeba_preprocessed_path>/<split>` where `<split>` corresponds to one of the available subsets: public, private_train, or private_test.

You can load the dataset using the following code:

```python
from modelinversion.datasets import CelebA64
from torchvision.transforms import ToTensor

dataset_path = "<celeba_preprocessed_path>/<split>"

dataset = CelebA64(dataset_path, output_transform=ToTensor())
```

In this example, CelebA64 refers to the CelebA dataset with a resolution of $64\times 64$ pixels. We also provide datasets at other resolutions, including: CelebA112, CelebA224 and  CelebA299.

### FaceScrub

The downloaded FaceScrub dataset is organized into the following structure:
```
<facescrub_download_path>
├── actors
└── actresses
```

The `dataset_path` corresponds to the `facescrub_download_path` where the dataset is downloaded.

You can load the dataset using the following code:

```python
from modelinversion.datasets import FaceScrub64
from torchvision.transforms import ToTensor

dataset_path = "<facescrub_download_path>"

train_dataset = FaceScrub64(dataset_path, train=True, output_transform=ToTensor())
test_dataset = FaceScrub64(dataset_path, train=False, output_transform=ToTensor())
```

In this example, FaceScrub64 refers to the CelebA dataset with a resolution of $64\times 64$ pixels. We also provide datasets at other resolutions, including: FaceScrub112, FaceScrub224 and  FaceScrub299.

### Labeled Datasets

For datasets generated by [top_k_selection.py](../examples/standard/dataset_preprocess/plgmi_top_k_selection.py) or [lokt_generation.py](../examples/standard/dataset_preprocess/lokt_generation.py). The dataset is organized into the following structure:
```
<dataset_path>
├── 0
├── 1
├── 2
├── 3
├── ...
```

You can load the dataset using the following code:
```python
from modelinversion.datasets import LabelImageFolder, Celeba64
from torchvision.transforms import ToTensor

# if the dataset is extracted by origin celeba dataset, use the series of CelebA64, CelebA112
dataset = LabelImageFolder(dataset_path, output_transform=ToTensor())

# otherwise, use LabelImageFolder
dataset = LabelImageFolder(dataset_path, transform=ToTensor())
```

### Public Datasets

Public Datasets contains FFHQ64, FFHQ256, MetFaces256. To use these datasets, just use `ImageFolder` from `torchvision.datasets`.

```python
from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor

dataset_path = "<dataset_path>"

dataset = ImageFolder(dataset_path, transform=ToTensor())
```

## Checkpoint Path


The format of the model ckeckpoint path should be `<model_path>/<model_name>.pth`.

You can load the dataset using the following codes:

```python
from modelinversion.models import (
    auto_classifier_from_pretrained,
    auto_generator_from_pretrained,
    auto_discriminator_from_pretrained,
)

target_model_ckpt_path = "<target_model_ckpt_path>"
eval_model_ckpt_path = "<eval_model_ckpt_path>"
generator_ckpt_path = "<generator_ckpt_path>"
discriminator_ckpt_path = "<discriminator_ckpt_path>"

target_model = auto_classifier_from_pretrained(target_model_ckpt_path)
eval_model = auto_classifier_from_pretrained(eval_model_ckpt_path)
generator = auto_generator_from_pretrained(generator_ckpt_path)
discriminator = auto_discriminator_from_pretrained(discriminator_ckpt_path)

```
